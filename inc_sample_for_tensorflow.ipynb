{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37ea7a6",
   "metadata": {},
   "source": [
    "# Intel® Neural Compressor Sample for Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b2d67",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is a demo to show an End-To-End pipeline to speed up AI model by Intel® Neural Compressor.\n",
    "\n",
    "1. Train a CNN AlexNet model by Keras and Intel Optimization for Tensorflow based on dataset MNIST.\n",
    "\n",
    "2. Quantize the frozen PB model file by Intel® Neural Compressor to INT8 model.\n",
    "\n",
    "3. Compare the performance of FP32 and INT8 model by same script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f09276",
   "metadata": {},
   "source": [
    "## Run in Intel® DevCloud\n",
    "\n",
    "### Find a Computing Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f031bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* How many compute servers are available?\n",
      "/bin/bash: pbsnodes: command not found\n",
      "0\n",
      "* How many of them are free?\n",
      "/bin/bash: pbsnodes: command not found\n",
      "0\n",
      "* What are the time limits for queued jobs?\n",
      "/bin/bash: qmgr: command not found\n",
      "* What is the configuration of the available compute servers?\n",
      "/bin/bash: pbsnodes: command not found\n"
     ]
    }
   ],
   "source": [
    "!echo \"* How many compute servers are available?\"\n",
    "!pbsnodes | grep \"^s\" | wc -l\n",
    "\n",
    "!echo \"* How many of them are free?\"\n",
    "!pbsnodes | grep \"state = free\" | wc -l\n",
    "\n",
    "!echo \"* What are the time limits for queued jobs?\"\n",
    "!qmgr -c 'p q batch' | grep walltime\n",
    "\n",
    "!echo \"* What is the configuration of the available compute servers?\"\n",
    "!pbsnodes | grep properties | sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51bc091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pbsnodes: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f07f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* How many compute servers are available?\n",
      "/bin/bash: pbsnodes: command not found\n",
      "0\n",
      "* How many of them are free?\n",
      "/bin/bash: pbsnodes: command not found\n",
      "0\n",
      "* What are the time limits for queued jobs?\n",
      "/bin/bash: qmgr: command not found\n",
      "* What is the configuration of the available compute servers?\n",
      "/bin/bash: pbsnodes: command not found\n"
     ]
    }
   ],
   "source": [
    "!echo \"* How many compute servers are available?\"\n",
    "!pbsnodes | grep \"^s\" | wc -l\n",
    "\n",
    "!echo \"* How many of them are free?\"\n",
    "!pbsnodes | grep \"state = free\" | wc -l\n",
    "\n",
    "!echo \"* What are the time limits for queued jobs?\"\n",
    "!qmgr -c 'p q batch' | grep walltime\n",
    "\n",
    "!echo \"* What is the configuration of the available compute servers?\"\n",
    "!pbsnodes | grep properties | sort | uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb0a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model by Keras/Tensorflow with MNIST\n",
      "Tensorflow version 2.5.0\n",
      "LPOT version 1.5.1\n",
      "Loading data ...\n",
      "Done\n",
      "train (60000, 28, 28, 1) (60000, 10) (60000,)\n",
      "test (10000, 28, 28, 1) (10000, 10) (10000,)\n",
      "2022-01-18 15:05:14.573294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 15:05:14.580953: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/jianyuzh/.conda/envs/user_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 256)         3211520   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,938,058\n",
      "Trainable params: 6,938,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2022-01-18 15:05:14.827058: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-18 15:05:14.850221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "100/100 [==============================] - 69s 684ms/step - loss: 0.5197 - accuracy: 0.8189 - val_loss: 0.0680 - val_accuracy: 0.9781\n",
      "Test score: 0.0679863691329956\n",
      "Test accuracy: 0.9781000018119812\n",
      "2022-01-18 15:06:40.176198: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-01-18 15:06:40.180747: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-01-18 15:06:40.190857: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"keras_tf_train_mnist.py\", line 77, in <module>\n",
      "    os.system(\"ls -la fp32_frezon.pb\")\n",
      "NameError: name 'os' is not defined\n",
      "Training is finished\n",
      "Enable Intel Optimization for Tensorflow by exporting TF_ENABLE_MKL_NATIVE_FORMAT=0\n",
      "Intel Optimized TensorFlow 2.5.0 and later require to set environment variable TF_ENABLE_MKL_NATIVE_FORMAT=0 before running Intel® Neural Compressor quantize Fp32 model or deploying the quantized model.\n",
      "Quantize Model by Intel Neural Compressor\n",
      "LPOT version 1.5.1\n",
      "2022-01-18 15:06:43 [WARNING] This API is going to be deprecated, please import lpot.experimental.Quantization, set the attributes about dataloader and metric, then use new __call__ method\n",
      "2022-01-18 15:06:43 [WARNING] force convert user raw model to lpot model, better initialize lpot.experimental.common.Model and set....\n",
      "2022-01-18 15:06:43 [INFO] loading session....\n",
      "2022-01-18 15:06:43.820390: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 15:06:43 [INFO] ConvertLayoutOptimizer elapsed time: 0.1 ms\n",
      "2022-01-18 15:06:43.974036: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-01-18 15:06:43.974240: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-01-18 15:06:44.002229: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "2022-01-18 15:06:44.051159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  model_pruner: Graph size after: 55 nodes (0), 68 edges (0), time = 0.218ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.054ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (-14), 40 edges (-28), time = 0.338ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.028ms.\n",
      "  loop_optimizer: Graph size after: 41 nodes (0), 40 edges (0), time = 0.101ms.\n",
      "  model_pruner: Graph size after: 41 nodes (0), 40 edges (0), time = 0.117ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.023ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 40 edges (0), time = 0.202ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.024ms.\n",
      "\n",
      "2022-01-18 15:06:44 [INFO] Pass GrapplerOptimizer elapsed time: 207.38 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 4.41 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass SplitSharedInputOptimizer elapsed time: 0.3 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass GraphFoldConstantOptimizer elapsed time: 4.31 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass FuseColumnWiseMulOptimizer elapsed time: 4.85 ms\n",
      "2022-01-18 15:06:44 [WARNING] From /home/jianyuzh/.conda/envs/user_tensorflow/lib/python3.7/site-packages/lpot/adaptor/tf_utils/util.py:318: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-01-18 15:06:44 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 18.35 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass GraphCseOptimizer elapsed time: 4.72 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 4.78 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass UpdateEnterOptimizer elapsed time: 4.45 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass ConvertLeakyReluOptimizer elapsed time: 4.55 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass InjectDummyBiasAddOptimizer elapsed time: 4.39 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass ConvertAddToBiasAddOptimizer elapsed time: 4.29 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass FuseTransposeReshapeOptimizer elapsed time: 4.13 ms\n",
      "2022-01-18 15:06:44 [INFO] Pass FuseConvWithMathOptimizer elapsed time: 4.07 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 15:06:44 [INFO] Pass Pre Optimization elapsed time: 378.2 ms\n",
      "2022-01-18 15:06:44 [INFO] Getting FP32 model baseline...\n",
      "2022-01-18 15:06:44 [INFO] Start to evaluate Tensorflow model...\n",
      "Loading data ...\n",
      "Done\n",
      "2022-01-18 15:06:44.960730: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-18 15:06:49 [INFO] Save tuning history to /ws1/jianyuzh/ws1/github/intel_neural_compressor_sample/lpot_workspace/2022-01-18_15-06-42/./history.snapshot\n",
      "2022-01-18 15:06:49 [INFO] FP32 baseline is: [accuracy: 0.9781, duration (seconds): 5.4853]\n",
      "2022-01-18 15:06:49 [WARNING] Found possible input node names: ['x'], output node names: ['Identity']\n",
      "2022-01-18 15:06:50 [INFO] loading session....\n",
      "2022-01-18 15:06:50 [WARNING] From /home/jianyuzh/.conda/envs/user_tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.\n",
      "2022-01-18 15:06:50.358768: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-01-18 15:06:50 [INFO] Pass Quantization elapsed time: 272.89 ms\n",
      "Loading data ...\n",
      "Done\n",
      "2022-01-18 15:06:51 [INFO] Pass QuantizedRNNConverter elapsed time: 2.72 ms\n",
      "2022-01-18 15:06:51 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 6.67 ms\n",
      "2022-01-18 15:06:51 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 2.79 ms\n",
      "2022-01-18 15:06:51 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 2.75 ms\n",
      "2022-01-18 15:06:51 [INFO] Pass MetaOpOptimizer elapsed time: 1.82 ms\n",
      "2022-01-18 15:06:51 [INFO] Pass PostCseOptimizer elapsed time: 105.83 ms\n",
      "2022-01-18 15:06:51 [INFO] |*Mixed Precision Statistics|\n",
      "2022-01-18 15:06:51 [INFO] +------------+-------+------+\n",
      "2022-01-18 15:06:51 [INFO] |  Op Type   | Total | INT8 |\n",
      "2022-01-18 15:06:51 [INFO] +------------+-------+------+\n",
      "2022-01-18 15:06:51 [INFO] |   Conv2D   |   6   |  6   |\n",
      "2022-01-18 15:06:51 [INFO] |   MatMul   |   1   |  1   |\n",
      "2022-01-18 15:06:51 [INFO] |  MaxPool   |   2   |  2   |\n",
      "2022-01-18 15:06:51 [INFO] | QuantizeV2 |   2   |  2   |\n",
      "2022-01-18 15:06:51 [INFO] | Dequantize |   2   |  2   |\n",
      "2022-01-18 15:06:51 [INFO] +------------+-------+------+\n",
      "2022-01-18 15:06:51 [INFO] Pass quantize model elapsed time: 2054.4 ms\n",
      "2022-01-18 15:06:51 [INFO] Start to evaluate Tensorflow model...\n",
      "Loading data ...\n",
      "Done\n",
      "2022-01-18 15:06:53 [INFO] Tune 1 result is: [accuracy: 0.9788, duration (seconds): 2.0942], Best tune result is: [accuracy: 0.9788, duration (seconds): 2.0942]\n",
      "2022-01-18 15:06:53 [INFO] Save tuning history to /ws1/jianyuzh/ws1/github/intel_neural_compressor_sample/lpot_workspace/2022-01-18_15-06-42/./history.snapshot\n",
      "2022-01-18 15:06:53 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit...\n",
      "2022-01-18 15:06:53 [INFO] Save deploy yaml to path /ws1/jianyuzh/ws1/github/intel_neural_compressor_sample/lpot_workspace/2022-01-18_15-06-42/deploy.yaml\n",
      "Save to alexnet_int8_model.pb\n",
      "Quantization is finished\n",
      "Execute the profiling_inc.py with FP32 model file\n",
      "Tensorflow version 2.5.0\n",
      "Loading data ...\n",
      "Done\n",
      "2022-01-18 15:06:56.158883: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 15:06:56.292221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-18 15:06:56.318232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "accuracy: 0.9781\n",
      "max throughput(fps): 1018.0218308351414\n",
      "latency(ms): 1.7654384885515486\n",
      "Save result to 32.json\n",
      "FP32 performance test is finished\n",
      "Execute the profiling_inc.py with INT8 model file\n",
      "Tensorflow version 2.5.0\n",
      "Loading data ...\n",
      "Done\n",
      "2022-01-18 15:07:09.794096: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 15:07:09.858571: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-18 15:07:09.882195: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "accuracy: 0.9782\n",
      "max throughput(fps): 3621.492527003808\n",
      "latency(ms): 0.8665121331506845\n",
      "Save result to 8.json\n",
      "INT8 performance test is finished\n",
      "Compare the Performance of FP32 and INT8 Models\n",
      "throughputs [1018.0218308351414, 3621.492527003808]\n",
      "latencys [1.7654384885515486, 0.8665121331506845]\n",
      "accuracys [0.9781, 0.9782]\n",
      "Save to fp32_int8_aboslute.png\n",
      "throughputs_times [1, 3.557381990554064]\n",
      "latencys_times [1, 0.49081978147061534]\n",
      "accuracys_times [0, 0.009999999999990905]\n",
      "Save to fp32_int8_times.png\n",
      "Please check the PNG files to see the performance!\n",
      "This demo is finished successfully!\n",
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "!bash inc_ft_mnist.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35833dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: invalid option -- '3'\r\n",
      "Try 'ls --help' for more information.\r\n",
      "error\r\n"
     ]
    }
   ],
   "source": [
    "!bash t.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29aceb5",
   "metadata": {},
   "source": [
    "![fp32_int8_aboslute.png](fp32_int8_aboslute.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64900d6",
   "metadata": {},
   "source": [
    "![fp32_int8_times.png](fp32_int8_times.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c31db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
